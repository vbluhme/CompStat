---
title: "Bivariate Smoothing (document)"
author: "Viktor Bluhme Jeppesen and Malte Nikolajsen"
date: "9/8/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(splines)

knitr::opts_chunk$set(cache = TRUE, dev.args = list(bg = 'transparent'), 
                      fig.align = "center", fig.pos="h", cache.lazy = TRUE,
                      out.width = "70%")
theme_set(theme_bw(base_size=12))
```

```{r NuukData, message=FALSE}
Nuuk <- read_table2("C:/Users/mn/Documents/CompStat/CompStat/data/nuuk.dat.txt", 
                    col_names = c("Year", 1:12), 
                    na = "-999", 
                    skip = 1) %>% 
  gather(key = "Month", value = "Temperature", -Year, convert = TRUE) %>% 
  mutate(Temperature = Temperature / 10) %>% 
  filter(Year > 1866)
Nuuk_year <- group_by(Nuuk, Year) %>% 
  summarise(
    Temperature = mean(Temperature),
    Median = median(Temperature),
    High = max(Temperature), 
    Low = min(Temperature)
  )
n <- nrow(Nuuk_year)
```

Form dataframe. Can select from `Nuuk_year` or `jepx`.

```{r}
x <- Nuuk_year$Year
y <- Nuuk_year$Temperature

df <- tibble(x, y)
```


```{r}
pp <- ggplot(df, aes(x, y)) +
  geom_point()
pp
```

## Splines

Given points $\{(x_1,y_1), \dots, (x_n, y_n)\}$, we want to implement the smoother which solves
\[
\min_{f \in C^2}\quad L(f) = \sum_{i=1}^n\big(y_i - f(x_i)\big)^2 + \lambda \|f''\|_2^2
\]
All solutions belong to the $n$-dimensional vector space consisting of cubic splines with knots in $\mathbf x = (x_1, \dots, x_n)$, independently of $\mathbf y$. Thus all candidate solutions can be written
\[
f = \sum_{i=1}^n \beta_i \varphi_i
\]
for a basis $\varphi_1, \dots, \varphi_n$ of cubic splines, or more concisely $\mathbf f = \boldsymbol \Phi \beta$ for $\mathbf f = (f(x_1), \dots, f(x_n))$ and $\boldsymbol \Phi_{ij} = \varphi_j(x_i)$. We use this to rewrite the loss function as
\[
L(f) = (\mathbf y - \boldsymbol \Phi\beta)'(\mathbf y - \boldsymbol \Phi\beta) + \lambda\beta'\boldsymbol \Omega\beta
\]
where
\[
\boldsymbol \Omega_{ij} = \langle\varphi_i'', \varphi_j''\rangle = \int \varphi_i''\varphi_j''\, dm.
\]
The minimizer is given by
\[
\hat{\mathbf{f}} = \boldsymbol\Phi(\boldsymbol\Phi'\boldsymbol\Phi + \lambda\boldsymbol\Omega)^{-1}\boldsymbol\Phi'\mathbf y \equiv \mathbf S_\lambda\mathbf y.
\]
We must overcome two computational challenges, namely 1) how to evaluate $\boldsymbol\Omega$ and 2) how to efficiently calculate $\mathbf S_{\lambda}$.

First, we find a function to evaluate $\boldsymbol\Omega$. From CSwR, using Simpson's rule:

```{r}
pen_mat <- function(inner_knots) {
  knots <- sort(c(rep(range(inner_knots), 3), inner_knots))
  d <- diff(inner_knots)  # The vector of knot differences; b - a 
  g_ab <- splineDesign(knots, inner_knots, derivs = 2) 
  knots_mid <- inner_knots[-length(inner_knots)] + d / 2
  g_ab_mid <- splineDesign(knots, knots_mid, derivs = 2)
  g_a <- g_ab[-nrow(g_ab), ]
  g_b <- g_ab[-1, ]
  (crossprod(d * g_a,  g_a) + 
      4 * crossprod(d * g_ab_mid, g_ab_mid) + 
      crossprod(d * g_b, g_b)) / 6 
}
```

We are now ready to write our first (slow) smoother function:

```{r}
Phi <- splineDesign(c(rep(range(x), 3), x), x)
Omega <- pen_mat(x)
  
smoother <- function(lambda) {
  Phi %*% solve(
    crossprod(Phi) + lambda * Omega, 
    t(Phi) %*% y
  )
}
```


```{r}
gcv <- function(lambda) {
  S <- Phi %*% solve(crossprod(Phi) + lambda * Omega, t(Phi))
  df <- sum(diag(S))  # The trace of the smoother matrix
  sum(((y - S %*% y) / (1 - df / length(y)))^2, na.rm = TRUE) 
}

lambda <- seq(50, 250, 2)
GCV <- sapply(lambda, gcv)
lambda_opt <- NULL
lambda_opt$gcv <- lambda[which.min(GCV)]
qplot(lambda, GCV) + geom_vline(xintercept = lambda_opt$gcv, color = "red")
```

We can test that this works:

```{r}
pp + geom_line(aes(y = smoother(lambda_opt$gcv)), col = "red")
```

Steps for efficient calculation of $\mathbf S_\lambda = \boldsymbol\Phi(\boldsymbol\Phi'\boldsymbol\Phi + \lambda\boldsymbol\Omega)^{-1}\boldsymbol\Phi'$

1. Single-value decomposition $\Phi = UDV'$.

2. Diagonalize the matrix $D^{-1}V'\Phi VD^{-1} = W\Gamma W'$.

3. Then 
\begin{equation}\label{eq:S_decomp}
\mathbf S_\lambda = \widetilde U(I + \lambda \Gamma)^{-1}\widetilde U'
\end{equation}
for $\widetilde U = UW$.

Step-by-step version for implementation:

- First, the coefficients $\hat\beta = \widetilde U'y$ are computed for expanding $y$ in the basis given by the columns of $\widetilde U$.

- Second, the $i$-th coefficient is shrunk towards $0$,
\[
\hat\beta_i(\lambda) = \frac{\hat\beta_i}{1+\lambda\gamma_i}.
\]

- Third, the smoothed values $\widetilde U\hat\beta_i(\lambda)$ are computed as an expansion using the shrunken coefficients.

```{r}
p <- 20
inner_knots <- seq(min(x), max(x), length.out = p-2)
Phi <- splineDesign(c(rep(range(inner_knots), 3), inner_knots), x)
Omega <- pen_mat(inner_knots)

Phi_svd <- svd(Phi)
Omega_tilde <- t(crossprod(Phi_svd$v, Omega %*% Phi_svd$v)) / Phi_svd$d
Omega_tilde <- t(Omega_tilde) / Phi_svd$d
Omega_tilde_svd <- svd(Omega_tilde)  
U_tilde <- Phi_svd$u %*% Omega_tilde_svd$u

# Decomposition, but fast
f_hat <- t(U_tilde) %*% y
f_hat <- f_hat / (1 + lambda_opt$gcv*Omega_tilde_svd$d)
f_hat <- U_tilde %*% f_hat


pp + geom_line(aes(y = f_hat), col = "red")
```

Warning: When $n < p$, the decomposition does not hold! This is why the splines diverge.

```{r, out.width = "100%", warning = FALSE}
plot_cols <- function(S, col_vec = 1:ncol(S)) {
  S %>% as_tibble() %>% mutate(n = row_number()) %>% pivot_longer(-n) %>% 
  mutate(name = str_replace(name, "V", ""),
         name = factor(name, levels = unique(name))) %>% 
  filter(name %in% col_vec) %>% 
  ggplot(aes(x = n, y = value, col = name)) +
  geom_line() +
  facet_wrap(~ name) +
  theme(legend.position = "none")
}

plot_cols(U_tilde)
```
We now implement spline smoothing with objective function for determining tuning parameter $\lambda$ being LOOCV. 
```{r LOOCV}
myLoocv <- function(
  x, #x-axis
  y, #y-axis
  p, #number of splines where p <n 
  interval, #interval in which to search for tuning parameter
  optimize = TRUE, #whether to optimize or not
  lambda = NULL #lambda value to compute with given we do not optimize
) {
  #Penalty matrix and Phi using exact integration
  pen_mat <- function(inner_knots) {
    knots <- sort(c(rep(range(inner_knots), 3), inner_knots))
    d <- diff(inner_knots)  # The vector of knot differences; b - a 
    g_ab <- splineDesign(knots, inner_knots, derivs = 2) 
    knots_mid <- inner_knots[-length(inner_knots)] + d / 2
    g_ab_mid <- splineDesign(knots, knots_mid, derivs = 2)
    g_a <- g_ab[-nrow(g_ab), ]
    g_b <- g_ab[-1, ]
    (crossprod(d * g_a,  g_a) + 
        4 * crossprod(d * g_ab_mid, g_ab_mid) + 
        crossprod(d * g_b, g_b)) / 6 
  }
  inner_knots <- seq(min(x), max(x), length.out = p - 2)
  Phi <- splineDesign(c(rep(range(inner_knots), 3), inner_knots), x)
  Omega <- pen_mat(inner_knots)
  
  #Implementation of 3.5.3
  Phi_svd <- svd(Phi)
  
  Omega_tilde <- t(crossprod(Phi_svd$v, Omega %*% Phi_svd$v)) / Phi_svd$d
    Omega_tilde <- t(Omega_tilde) / Phi_svd$d
  Omega_tilde_svd <- svd(Omega_tilde)  
  
  U_tilde <- Phi_svd$u %*% Omega_tilde_svd$u
  
  Gamma <- Omega_tilde_svd$d
  n <- length(Gamma)
  
  #Implementation of smoother matrix and leave-one-out cross-validation from 3.1.3
  smoother <- function(lambda, n) U_tilde %*% solve(diag(n) + lambda * diag(Gamma)) %*% t(U_tilde)
  
  obj <- function(lambda, n) {
    S <- smoother(lambda, n)
    sum(((y - S %*% y) / (1 - diag(S)))^2)
  }
  
  #Minimizing LOOCV in interval
  if(optimize == TRUE){lambda <- optimize(obj, interval, n = n)$minimum}
  list(x = x, y = y, f_hat = c(smoother(lambda, n) %*% y), inner_knots = inner_knots, lambda = lambda)
}
```
Comparing with `smooth.spline`, we supply the argument `cv = TRUE` such that it uses LOOCV as well.
Had it used GCV, our results may differ widely.
Another thing to keep in mind is the number of splines being used `nknots`. 
Given we want $p$ splines, we supply `knots` with the value `p - 2`, though we could simply use the algorithm that `smooth.spline` uses to select the amount of knots, `.nknots.smspl`.
```{r LOOCV versus smooth.spline}
#Using LOOCV 
p <- 50
mySmooth <- myLoocv(x, y, p, c(1, 100))
smooth <- smooth.spline(x, y, cv = TRUE, nknots = p - 2)

#Plot of the two spline smoothers
plot(x, y, 
     main = "Spline smoothing with our implementation and R's smooth.spline()",
     xlab = TeX("$x$"),
     ylab = TeX("$S_{\\lambda} y$"),
     cex = 0.6,
     pch = 16)
lines(x, mySmooth$f_hat, col = "blue")
lines(x, smooth$y, col = "red")
legend(830, 6, col = c("blue", "red"), lwd = 1, lty = 1, legend = TeX(c("Our $\\hat{f}$", "R's $\\hat{f}$")))

#Plot of differences 
plot(x, mySmooth$f_hat - smooth$y,
     type = "l",
     xlab = TeX("$x$"),
     ylab = TeX("$S_{\\lambda} y$"),
     main = "Numeric difference between our implementation and R's implementation")
range(mySmooth$f_hat - smooth$y)
```
Observing the plot of the spline smoothing, the smoothers seem to be approximately the same, and as can be seen by their numeric difference, they vary at most by 0.09.  

Next up would be to compare their performance.
We expect our method to be much slower than that of `smooth.spline`.
This has mainly to do with it using Fortran while we are left with R's native matrix computations. 
Using `microbenchmark`, we are able to measure their computation speeds on simulated data and plot them.
Since we are not to test for their root-search efficiency, we will supply these beforehand. 
```{r benchmark}
#Simulated data
n <- 1000
x <- 1:n
y <- c(0, cumsum(rnorm(n-1, sd = 0.6)))
lambda_opt <- c(myLoocv(x, y, p, c(1, 200))$lambda, smooth.spline(x, y, cv = TRUE, nknots = p - 2)$lambda)

#Plot of computation times
myBench <- microbenchmark("Our implementation" = myLoocv(x, y, p, c(1, 200), optimize = FALSE, lambda = lambda_opt[1]),
                          "R's implementation" = smooth.spline(x, y, cv = TRUE, nknots = p - 2, lambda = lambda_opt[2]))
autoplot(myBench) + geom_jitter(position = position_jitter(0.2, 0), aes(color = expr), alpha = 0.4) + aes(fill = I("gray")) + theme(legend.position = "none")
```
As foreseen, our method is much less efficient than `smooth.spline`.
We continue the comparison by seeing the methods performance for different number of splines $p$. 
```{r Different number of splines}
p <- c(100, 200, 300, 400, 500, 600, 700, 800)
lambda_opt <- rep(NA, 16)
for(i in 1:8){
  lambda_opt[2 * i] <- myLoocv(x, y, p[i], c(1, 200))$lambda
  lambda_opt[2 * i - 1] <- smooth.spline(x, y, cv = TRUE, nknots = p[i] - 2)$lambda
}
myBench <- microbenchmark( 
  "R's  implementation, p = 100" = smooth.spline(x, y, cv = TRUE, nknots = p[1] - 2, lambda = lambda_opt[1]),
  "R's  implementation, p = 200" = smooth.spline(x, y, cv = TRUE, nknots = p[2] - 2, lambda = lambda_opt[3]),
  "R's implementation, p = 300" = smooth.spline(x, y, cv = TRUE, nknots = p[3] - 2, lambda = lambda_opt[5]),
  "R's implementation, p = 400" = smooth.spline(x, y, cv = TRUE, nknots = p[4] - 2, lambda = lambda_opt[7]),
  "R's implementation, p = 500" = smooth.spline(x, y, cv = TRUE, nknots = p[5] - 2, lambda = lambda_opt[9]),
  "R's implementation, p = 600" = smooth.spline(x, y, cv = TRUE, nknots = p[6] - 2, lambda = lambda_opt[11]),
  "R's implementation, p = 700" = smooth.spline(x, y, cv = TRUE, nknots = p[7] - 2, lambda = lambda_opt[13]),
  "R's implementation, p = 800" = smooth.spline(x, y, cv = TRUE, nknots = p[8] - 2, lambda = lambda_opt[15]),
  "Our implementation, p = 100" = myLoocv(x, y, p[1], c(1, 200), optimize = FALSE, lambda = lambda_opt[2]),
  "Our implementation, p = 200" = myLoocv(x, y, p[2], c(1, 200), optimize = FALSE, lambda = lambda_opt[4]),
  "Our implementation, p = 300" = myLoocv(x, y, p[3], c(1, 200), optimize = FALSE, lambda = lambda_opt[6]),
  "Our implementation, p = 400" = myLoocv(x, y, p[4], c(1, 200), optimize = FALSE, lambda = lambda_opt[8 ]),
  "Our implementation, p = 500" = myLoocv(x, y, p[5], c(1, 200), optimize = FALSE, lambda = lambda_opt[10]),
  "Our implementation, p = 600" = myLoocv(x, y, p[6], c(1, 200), optimize = FALSE, lambda = lambda_opt[12]),
  "Our implementation, p = 700" = myLoocv(x, y, p[7], c(1, 200), optimize = FALSE, lambda = lambda_opt[14]),
  "Our implementation, p = 800" = myLoocv(x, y, p[8], c(1, 200), optimize = FALSE, lambda = lambda_opt[16])
)
autoplot(myBench) + geom_jitter(position = position_jitter(0.2, 0), aes(color = expr), alpha = 0.4) + aes(fill = I("gray")) + theme(legend.position = "none")
```







